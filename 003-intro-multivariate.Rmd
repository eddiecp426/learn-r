---
title: "Introduction to Multivariate Statistics in R"
author: "Jeff Oliver"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    css: stylesheets/markdown-styles.css
---

## TODO:
1. ~Add instructions for downloading data then exporting as CSV file~
2. Break apart PCA code in stepwise fashion
3. Provide rationale for why PCA
4. Add (advanced) code for detecting the number of clusters
5. Provide spreadsheet software info (Excel, LibreOffice) on 000-setup-instructions page


##See: 

###PCA:

+ http://www.statmethods.net/advstats/factor.html
+ https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/
+ [Why PCA? (or "how to explain PCA to your grandmother")](http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues)
+ [Principal Components Regression](https://www.r-bloggers.com/performing-principal-components-regression-pcr-in-r/)

###Clustering, K-means:

+ https://www.r-bloggers.com/k-means-clustering-in-r/
+ http://www.statmethods.net/advstats/cluster.html
+ https://stat.ethz.ch/R-manual/R-devel/library/stats/html/kmeans.html
+ http://stackoverflow.com/questions/15376075/cluster-analysis-in-r-determine-the-optimal-number-of-clusters
+ [Wikipedia entry for the various ways of determining the optimal number of clusters](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set)
+ [Programmatically identifying the "elbow"](http://stackoverflow.com/questions/2018178/finding-the-best-trade-off-point-on-a-curve)

###Ignore these:

+ http://www.statmethods.net/stats/regression.html _ignore_
+ https://www.r-bloggers.com/r-tutorial-series-anova-tables/ _ignore_

An introduction to using the R statistics package and the RStudio interface for multivariate statistics.

####Learning objectives
1. Prepare data in spreadsheet program (e.g. Excel, LibreOffice Calc) for export to R
2. Read data from files into R
3. Run Principal Components Analysis (PCA) and graphically display results
4. Run K-means clustering analysis
5. Run DFA?

##Setup
###Workspace organization
First we need to setup our development environment. We need to create two folders: 'data' will store the data we will be analyzing, and 'output' will store the results of our analyses.
```{r, eval = FALSE}
dir.create(path = "data")
dir.create(path = "output")
```

###Preparing data in a format R can read
+ Download data file from [https://jcoliver.github.io/learn-r/data/otter-mandible-data.xlsx](https://jcoliver.github.io/learn-r/data/otter-mandible-data.xlsx) or [http://tinyurl.otter-data](http://tinyurl.otter-data) (the latter just re-directs to the former).
+ Open this file, otter-mandible-data.xlsx, in spreadsheet program like Microsoft Excel<sup>&reg;</sup> or LibreOffice Calc.
+ Save a copy of the file as a CSV (comma-separated values) file named 'otter-mandible-data.csv' in the data folder you created above:
    + In MS Excel<sup>&reg;</sup>, select File > Save As... and in the dialog that appears, select CSV from the type dropdown menu.
    + In LibreOffice Calc, select File > Save As... and in the dialog that appears, select Text CSV (.csv) in the Format dropdown in the lower-right portion of the dialog.

###Reading data into R
```{r}
otter <- read.csv(file = "data/otter-mandible-data.csv", header = TRUE)
```
  
Missing data can cause problems in downstream analyses, so we will just remove any rows that have missing data. Here we replace the original data object `otter` with one in which there are no missing values. Note, this _does not_ alter the data in the original file we read into R; it only alters the data object `otter` currently in R's memory.
```{r}
otter <- na.omit(otter)
```

##PCA
Why PCA? Very briefly, Principal Components Analysis is a way of re-describing the variation observed in your data. It serves as a means of reducing the dimensionality of data (i.e. reducing the number of predictor variables) and is often used for exploratory analyses. The full rationale and mathematically underpinnings are waaaaaaaay beyond the scope of this lesson, and other resources already do a fairly good job of explaining PCA. If you want a few perspectives for a relatively novice audience, check out this [Why PCA? (or "how to explain PCA to your grandmother")](http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues) thread at Stack Overflow. If you are more inclined to print media, I highly recommend B.F.J. Manly's _Multivariate Statistical Methods: A primer_ [*TODO: REF*], which provides an excellent introduction to a variety of multivariate statistic topics.

+ Do pca
+ point out
    + summary for the proportion of variance (remember if you want to show how this is calculated, the standard deviation has to be squared to get variance)
    + loadings for what points along an axis actually mean
+ do call to biplot (ugly)?
+ do plot from fit$x
  + make plot nicer

```{r}
pca.fit <- prcomp(x = otter[, -1], scale. = TRUE)
species <- unique(otter$species)
legend.cols <- c("black", "forestgreen", "cadetblue", "darkred")
pt.cols <- rep(x = legend.cols[1], length = nrow(otter))
pt.cols[otter$species == species[2]] <- legend.cols[2]
pt.cols[otter$species == species[3]] <- legend.cols[3]
pt.cols[otter$species == species[4]] <- legend.cols[4]
plot(x = pca.fit$x[, 1],
     y = pca.fit$x[, 2],
     xlab = "PC 1",
     ylab = "PC 2",
     pch = 19,
     col = pt.cols)
legend("bottomleft", legend = species, pch = 19, col = legend.cols, cex = 0.8)

boxplot(formula = jaw.length ~ species, data = otter)
boxplot(formula = mandibular.ramus.height ~ species, data = otter)
```

+ Standardize variables, mean = 0, variance = 1
+ eigenvalues are variance by each component
  + Get % variance for i^th^ component via eig~i~/n, where n is the total number of components (total number of variables)
+ Look at loadings to explain variation in data

***

##Clustering with K-means

```{r}
# Scale data & drop species column
otter.scaled <- scale(x = otter[, -1])
wss <- numeric(10)
for (i in 1:10) {
  kmeans.fit <- kmeans(x = otter.scaled, centers = i, nstart = 10)
  wss[i] <- kmeans.fit$tot.withinss
}
plot(x = c(1:length(wss)), y = wss, xlab = "Number of clusters, K", ylab = "Total within SS", type = "b")

# Percentage of variance explained is the ratio of the between-group variance to the total 
# variance, also known as an F-test. A slight variation of this method plots the curvature 
# of the within group variance. https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set
# 

```

Abstracting the number of clusters to analyze
```{r}
```

Apply "Elbow" method based on percentage of variance explained
```{r}
# Advanced
```

See how clustering aligned with species
```{r}
# Run kmeans again for K = 4, to get clustering info
otter.k.4 <- kmeans(x = otter.scaled, centers = 4, nstart = 10)
otter.clusters <- data.frame(otter, cluster = otter.k.4$cluster)
assignments <- table(otter.clusters$species, otter.clusters$cluster)
assignments

```

***

###References

See: [Bibliographies in RStudio](http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html)

***

Questions?  e-mail me at <a href="mailto:jcoliver@email.arizona.edu">jcoliver@email.arizona.edu</a>.